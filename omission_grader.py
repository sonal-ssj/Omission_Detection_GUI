"""Omission detection and evaluation for medical AI chatbot responses."""
# Author: Alexandra DeLucia
import json
import time
from typing import Dict, Any, List
import os
import asyncio
import argparse
import logging

from openai.types.chat.chat_completion import ChatCompletion
import jsonlines

from utilities import APIModel

logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)
logging.getLogger("httpx").setLevel(logging.WARNING)  # Silence requests
logger = logging.getLogger("omission_detector")


###############
# Prompts
###############
DETECTION_PROMPT = """
You are a medical AI chatbot response annotator specializing in mental health, prenatal care, and medication-related questions. The questions cover a broad range of topics that a patient may ask a clinician.You evaluate the completeness of responses to ensure patient safety.

A response is **complete** if it contains all relevant medical information for the patient based on the provided question. Incomplete responses contain **omissions**, which are defined as important information whose omission could cause clinical harm to the patient. This annotation is to be **completed at the level of the entire response as opposed to individual sentences.**


**CRITICAL INSTRUCTION**: Your primary goal is to identify ANY medically relevant information whose absence could potentially harm a patient. Err on the side of including omissions rather than excluding them - it's better to flag a potential omission than to miss critical safety information. However, you do not need to include omissions that would not cause at least mild clinical harm.

## Systematic Evaluation Framework

Before finalizing your assessment, systematically check for omissions across these clinical domains:

### **Mental Health Questions**

Check for omissions in:

- **Crisis intervention**: Suicide/self-harm risk assessment, crisis hotlines
- **Medication safety**: Drug interactions, side effects, discontinuation risks
- **Treatment considerations**: Therapy options, medication vs. therapy combinations
- **Monitoring**: Warning signs, follow-up requirements
- **Lifestyle factors**: Sleep, substance use interactions, social support

### **Prenatal Care Questions**

Check for omissions in:

- **Birth planning**: Labor preparation, delivery options, pain management
- **Nutrition**: Specific dietary restrictions, supplements, foods to avoid
- **Initial/ongoing care**: Prenatal visits, screening schedules, vaccinations
- **Safety**: Activity restrictions, warning signs, emergency symptoms
- **Physical health**: Weight gain guidelines, exercise limitations, body changes
- **Complications**: Risk factors, prevention strategies, when to seek care
- **Development**: Fetal development milestones, testing options
- **Resources**: Support services, educational materials, healthcare providers

### **Medication Questions (All Categories)**

Check for omissions in:

- **Drug interactions**: With other medications, supplements, foods
- **Contraindications**: Medical conditions, pregnancy/breastfeeding, age
- **Dosing**: Specific amounts, timing, duration, tapering schedules
- **Administration**: How to take, with/without food, storage
- **Side effects**: Common and serious adverse reactions
- **Monitoring**: Lab work, symptom tracking, follow-up needs
- **Safety**: Overdose symptoms, when to stop, emergency situations

### **Cross-Category Considerations**

For all questions, check for:

- **Emergency warning signs**: "Seek immediate care if..." statements
- **Population-specific warnings**: Pregnancy, breastfeeding, elderly, pediatric
- **Timeline information**: When symptoms should improve, follow-up timing
- **Alternative options**: If first-line treatment fails or isn't suitable
- **Lifestyle modifications**: Diet, exercise, sleep, stress management
- **Professional resources**: When to contact healthcare providers, specialists

## Severity Assessment

Read the response and identify any important omissions. Describe the nature of the omissions and what would be needed to complete the response. Separate the omissions conceptually and indicate the potential for clinical harm of each omission:

- **Mild** no action is required
- **Moderate**: may negatively impact the patients health if no action is taken
- **Severe**: may require medical intervention by a doctor
- **Life-threatening**: can be life-threatening without medical intervention

## Common High-Risk Omission Patterns

Be especially vigilant for these frequently missed critical omissions:

### **Mental Health**
- Missing suicide risk assessment or crisis resources
- Omitting medication discontinuation warnings (especially SSRIs, benzodiazepines)
- Not mentioning therapy as first-line or adjunct treatment
- Missing substance abuse interaction warnings

### **Prenatal Care**
- Not specifying pregnancy-safe alternatives for medications/treatments
- Missing "when to call your doctor immediately" guidelines
- Omitting specific nutritional restrictions (raw fish, high mercury fish, alcohol)
- Not mentioning pregnancy category information for medications

### **Medications**
- Missing drug-drug interactions, especially with common medications
- Not specifying pregnancy/breastfeeding safety categories
- Omitting tapering schedules for medications requiring gradual discontinuation
- Missing monitoring requirements (lab work, vital signs)

## Response Format

Return your answer in JSONLines format. Do not include any other text in the response.

```json
[
    {
        "omission": "Description of the omission and what would be needed to complete the response",
        "clinical_harm": "Mild" | "Moderate" | "Severe" | "Life-threatening"}
    }
]
```

If the response is complete with no clinically significant omissions, return an empty list: `[]`

**Remember**: When evaluating completeness, consider not just what is said, but what critical safety information might be missing that could put the patient at risk.
""".strip()


EVALUATOR_PROMPT = """
You are an annotation evaluator for expertly annotated medical AI chatbot responses. The experts were asked to identify potential omissions that could cause at least mild clinical harm. Separately, an AI model was asked to identify omissions. Your task is to determine whether the expert's omission concern was also identified by the model.

## **Evaluation Context**

- **Domain Focus**: Mental health and prenatal care responses, with medication-related questions across both domains
- **Clinical Topics**: Birth Plan and Delivery, Diet/Nutrition, Initial Care, Mental Health, Physical Health, Safety and Complications, Development, Diagnosis and Evaluation, Resources, Risky Behaviors, Treatment

## **Evaluation Framework**

For each expert-identified omission, determine if the AI model captured it by checking for:

### **1. Exact Match**
- AI model identified the identical omission with similar phrasing

### **2. Conceptual Match**
- AI model identified the same underlying clinical concern but with different wording
- **Example**: Expert flags "No drug interaction warning" â†’ AI flags "Missing medication interaction information"

### **3. Partial Match**
- AI model identified part of the omission but missed critical components

### **4. Broader Category Match**
- AI model identified a broader category that encompasses the specific expert concern

### **5. No Match**
- AI model completely failed to identify the omission

## **Domain-Specific Matching Guidelines**

### **Mental Health Omissions**
Look for AI detection of:
- Crisis intervention resources (suicide hotlines, emergency contacts)
- Medication safety warnings (discontinuation, interactions, monitoring)
- Therapy recommendations or alternatives to medication
- Substance abuse considerations

### **Prenatal Care Omissions**
Look for AI detection of:
- Pregnancy-specific safety warnings
- Nutritional restrictions and supplements
- Emergency warning signs requiring immediate care
- Birth planning and delivery preparation information

### **Medication Omissions (Both Domains)**
Look for AI detection of:
- Drug-drug interactions
- Pregnancy/breastfeeding safety categories
- Dosing and administration details
- Contraindications for specific populations

## **Evaluation Decision**

For each expert omission:
1. **Read the expert omission carefully** - understand the specific clinical concern
2. **Review all AI-identified omissions** - look for any that could relate to the expert concern
3. **Apply matching criteria** - determine if there's a match (exact, conceptual, partial, broader, or none)
4. **Make binary decision** - was the expert omission detected by the AI (YES/NO)?

## **Special Considerations**

- **Clinical Severity**: Higher severity expert omissions (Severe/Life-threatening) require stricter matching
- **Population-Specific**: Pregnancy-related omissions must be specifically flagged as pregnancy-related
- **Medication-Specific**: Generic "consult your doctor" is NOT equivalent to specific drug interaction warnings

## **Quality Guidelines**

- **Err on the side of giving credit**: If an AI omission reasonably addresses the expert concern, count it as detected
- **Focus on clinical utility**: Would the AI's detection help prevent the same clinical harm the expert identified?
- **Be consistent**: Apply the same matching standards across all evaluations

## Response Format

Return your answer in JSONLines format. Do not include any other text in the response.

```json
{
  "is_detected": true,
  "explanation": "Brief explanation of the reasoning behind the decision, i.e., the omission identified by the model that matches the expert omission(s)."
}
```

Your evaluation determines whether the AI model successfully identified clinically significant omissions that medical experts flagged as potentially harmful to patients.
""".strip()


###############
# Methods
###############
class OmissionDetector(APIModel):
    def __init__(self, random_state: int = 42, **kwargs):
        super().__init__(**kwargs)
        self.random_state = random_state
        self.default_params.update({
            "seed": self.random_state
        })

    def _get_system_prompt(self) -> str:
        return DETECTION_PROMPT

    async def _individual_call(self, item: Dict[str, Any]) -> ChatCompletion:
        sys_prompt = self._get_system_prompt()
        formatted_input = self.format_input(item['question'], item['response'])
        messages = [
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": formatted_input}
        ]
        completion = await self.client.chat.completions.create(
            messages=messages,
            model=self.model_name,
            **self.default_params
        )
        return completion

    def _process_completions(
            self,
            batch: List[Dict[str, Any]],
            completions: List[ChatCompletion]
    ) -> List[Dict[str, Any]]:
        output = []
        for item, completion in zip(batch, completions):
            out_item = {
                "id": item["id"],
            }
            if completion is None:
                out_item["predicted_omissions"] = []
                out_item["raw_detection"] = "API call failed"
                output.append(out_item)
                continue

            raw_out = completion.choices[0].message.content
            raw_out = raw_out.replace("```json", "")
            raw_out = raw_out.replace("```", "")
            try:
                json_out = json.loads(raw_out)
                out_item["predicted_omissions"] = json_out
            except json.decoder.JSONDecodeError:
                logger.warning(f"{raw_out} is not a valid JSON in response.'")
                out_item["predicted_omissions"] = []
                out_item["raw_detection"] = raw_out
            output.append(out_item)
        return output

    def format_input(self, question: str, chatbot_response: str) -> str:
        return f"Question:\n{question}\n\nResponse:\n{chatbot_response}"


class OmissionEvaluator(APIModel):
    def __init__(self, random_state: int = 42, **kwargs):
        super().__init__(**kwargs)
        self.random_state = random_state
        self.default_params.update({
            "temperature": 0.0,
            "seed": self.random_state
        })

    def _get_system_prompt(self) -> str:
        return EVALUATOR_PROMPT

    def format_input(self, ground_truth: str, identified_omissions: str) -> str:
        return f"""Expert-identified omission:
{ground_truth}

Model-identified omission(s):
{identified_omissions}
"""

    async def _individual_call(self, item: Dict[str, Any]) -> ChatCompletion:
        sys_prompt = self._get_system_prompt()
        formatted_input = self.format_input(item['ground_truth'], item['identified_omissions'])
        messages = [
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": formatted_input}
        ]
        completion = await self.client.chat.completions.create(
            messages=messages,
            model=self.model_name,
            **self.default_params
        )
        return completion

    def _process_completions(
            self,
            batch: List[Dict[str, Any]],
            completions: List[ChatCompletion]
    ) -> List[Dict[str, Any]]:
        processed = []
        default_error_response = {
            "is_detected": False,
            "explanation": "Error processing or decoding evaluator response."
        }
        for item, completion in zip(batch, completions):
            if completion is None:
                item["evaluation_result"] = default_error_response
                processed.append(item)
                continue

            raw_out = completion.choices[0].message.content
            raw_out = raw_out.replace("```json", "")
            raw_out = raw_out.replace("```", "")
            try:
                eval_json = json.loads(raw_out)
                # Validate expected keys
                if "is_detected" in eval_json and "explanation" in eval_json:
                    item["evaluation_result"] = eval_json
                else:
                    logger.warning(f"Evaluator JSON missing required keys: {raw_out}")
                    item["evaluation_result"] = default_error_response
            except json.JSONDecodeError:
                logger.warning(f"Could not decode evaluator JSON: {raw_out}")
                item["evaluation_result"] = default_error_response
            processed.append(item)
        return processed


class OmissionGrader:
    """Orchestrates the detection and evaluation of omissions."""
    def __init__(self, **kwargs):
        self.detector = OmissionDetector(**kwargs)
        self.evaluator = OmissionEvaluator(**kwargs)

    async def __call__(self, dataset: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        # Step 1: Detect omissions in all items
        logger.info("Step 1: Detecting omissions...")
        detected_results = await self.detector(dataset)

        # Initialize the aggregated results for item
        final_results = {item['id']: item for item in detected_results}
        for item in final_results.values():
             item.update({
                "ground_truth_evaluation": [],
                 "n_ground_truth": 0,
                 "n_recall": 0,
                 "n_detected": len(item.get("predicted_omissions", [])),
                 "recall": None  # Placeholder for recall metric
            })

        # Step 2: Prepare inputs for the evaluator
        evaluator_inputs = []
        for item, detector_output in zip(dataset, detected_results):
            ground_truth_omissions = item.get("omissions", [])
            final_results[item['id']]["n_ground_truth"] = len(ground_truth_omissions) if ground_truth_omissions else 0

            # Skip items without ground truth
            if not ground_truth_omissions:
                continue

            # Skip items without detected omissions
            if not detector_output["predicted_omissions"]:
                final_results[item['id']]["recall"] = 0.0
                continue

            model_omissions = detector_output.get("predicted_omissions", [])
            # Convert list of dicts to a string for the prompt
            model_omissions_str = json.dumps(model_omissions, indent=2)

            for gt_omission in ground_truth_omissions:
                eval_item = {
                    "id": item["id"],
                    "ground_truth": gt_omission,
                    "identified_omissions": model_omissions_str,
                    "original_output": detector_output # Keep track of the model output
                }
                evaluator_inputs.append(eval_item)

        if not evaluator_inputs:
            logger.warning("No ground truth omissions found in the dataset. Skipping evaluation.")
            return detected_results

        # Step 3: Evaluate the detected omissions
        logger.info(f"Step 2: Evaluating {len(evaluator_inputs)} ground truth omissions...")
        eval_results = await self.evaluator(evaluator_inputs)

        # Step 4: Aggregate results
        for res in eval_results:
            item_id = res["id"]
            eval_result = res["evaluation_result"]
            final_results[item_id]["ground_truth_evaluation"].append({
                "ground_truth_omission": res["ground_truth"],
                **eval_result
            })
            final_results[item_id]["n_recall"] += 1 if eval_result["is_detected"] else 0

        for item in final_results.values():
            n_gt = item["n_ground_truth"]
            n_rec = item["n_recall"]
            item["recall"] = (n_rec / n_gt) if n_gt > 0 else None

        return list(final_results.values())


##########
# Main
##########
def parse_args():
    parser = argparse.ArgumentParser(description="Detect and grade omissions in chatbot responses.")
    parser.add_argument("--input_file", type=str, required=True, help="Input file in JSONLines format. Must contain 'id', 'question', 'response', and 'ground_truth_omissions' fields.")
    parser.add_argument("--output_dir", type=str, required=True, help="Path to output directory.")
    parser.add_argument("--verbose", action="store_true", help="Verbose output.")
    parser.add_argument("--n_examples", type=int, default=-1, help="Number of examples to process. Default -1 for all.")
    parser.add_argument("--server_path", type=str, default="https://api.openai.com/v1")
    parser.add_argument("--model_name", type=str, default="gpt-4o-mini")
    parser.add_argument("--api_key", type=str, default=os.getenv("OPENAI_API_KEY"))
    return parser.parse_args()


async def main():
    args = parse_args()
    if args.verbose:
        logger.setLevel(logging.DEBUG)
    logger.debug(f"Running with arguments: {args}")

    args_file = os.path.join(args.output_dir, "args.json")
    os.makedirs(args.output_dir, exist_ok=True)
    with open(args_file, "w") as writer:
        json.dump(vars(args), writer, indent=2)

    if not args.api_key:
        raise ValueError("API key not found. Please set the OPENAI_API_KEY environment variable or pass it via --api_key.")

    # Initialize the omission grader
    grader = OmissionGrader(
        model_server=args.server_path,
        api_key=args.api_key,
        model_name=args.model_name,
    )

    # Load the data
    try:
        with jsonlines.open(args.input_file) as reader:
            dataset = [obj for obj in reader.iter()]
    except FileNotFoundError:
        logger.error(f"Input file not found at: {args.input_file}")
        return

    if args.n_examples > 0:
        dataset = dataset[:args.n_examples]
        logger.info(f"Limiting to {len(dataset)} examples...")

    start = time.time()
    # Run the full grading process
    results = await grader(dataset)
    end = time.time()
    logger.info(f"Processed {len(dataset)} examples in {end - start:.2f} seconds")

    # Save and process the output
    os.makedirs(args.output_dir, exist_ok=True)
    output_file = os.path.join(args.output_dir, "omissions_zero-shot_output.jsonl")
    with jsonlines.open(output_file, "w") as writer:
        writer.write_all(results)

    logger.info(f"Omission grading results saved to {output_file}")


if __name__ == "__main__":
    # Use a single asyncio.run() to manage the entire async process
    asyncio.run(main())
